{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqupA2u4lW7ngqQvZHIhkj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohithr2511/FaceTextSummarization/blob/main/FaceTextSummarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tLm5DHzf7oom"
      },
      "outputs": [],
      "source": [
        "## Necessary libraries\n",
        "import argparse\n",
        "import os\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading model and tokenizer\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhs7O3Uq7w4t",
        "outputId": "42a6bef2-aeac-4c46-a74c-2621cdab8099"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunking text to fit model's input limits\n",
        "def chunk_text(text, max_tokens=800):\n",
        "    words = text.split()\n",
        "    for i in range(0, len(words), max_tokens):\n",
        "        yield \" \".join(words[i:i + max_tokens])"
      ],
      "metadata": {
        "id": "gOU4U22U8O77"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization function\n",
        "def summarize_text(text):\n",
        "    chunks = list(chunk_text(text))\n",
        "    summary = \"\"\n",
        "    for chunk in tqdm(chunks, desc=\"Summarizing\"):\n",
        "        result = summarizer(chunk, max_length=200, min_length=100, do_sample=False)[0]\n",
        "        summary += result['summary_text'] + \" \"\n",
        "    return summary.strip()"
      ],
      "metadata": {
        "id": "9NyWohEV8biL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: File I/O\n",
        "input_path = \"/content/input1.txt\"   # input1.txt path\n",
        "output_path = \"/content/output_summary.txt\""
      ],
      "metadata": {
        "id": "8Yy37O2k8ehB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading input text\n",
        "with open(input_path, 'r', encoding='utf-8') as file:\n",
        "    text = file.read()"
      ],
      "metadata": {
        "id": "tUShLxI--nuq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating summary\n",
        "summary = summarize_text(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArgqoTJw-qRp",
        "outputId": "89d268a7-8a99-4ab8-bf8c-75fd41d826db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Summarizing:   0%|          | 0/1 [00:00<?, ?it/s]Your max_length is set to 200, but your input_length is only 179. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
            "Summarizing: 100%|██████████| 1/1 [00:29<00:00, 29.33s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving summary to output file\n",
        "with open(output_path, 'w', encoding='utf-8') as file:\n",
        "    file.write(summary)\n",
        "\n",
        "print(f\"✅ Summary saved to: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RbYWp6P-tTt",
        "outputId": "fa841a57-6227-4945-d7c9-58eceabf7c8a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Summary saved to: /content/output_summary.txt\n"
          ]
        }
      ]
    }
  ]
}